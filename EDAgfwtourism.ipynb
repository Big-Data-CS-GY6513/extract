{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec91843e-423b-4809-b16a-293994734d06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.add_packages(\"org.mongodb.spark:mongo-spark-connector_2.12:2.4.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d2be95e-5651-4804-8a47-50e1c72d97c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/erinmiller/Library/Python/3.9/lib/python/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/erinmiller/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/erinmiller/.ivy2/jars\n",
      "org.mongodb.spark#mongo-spark-connector_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-9a37d556-13cb-406e-9fce-3ec1e74014b7;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.mongodb.spark#mongo-spark-connector_2.12;2.4.2 in central\n",
      "\tfound org.mongodb#mongo-java-driver;3.12.5 in central\n",
      ":: resolution report :: resolve 239ms :: artifacts dl 15ms\n",
      "\t:: modules in use:\n",
      "\torg.mongodb#mongo-java-driver;3.12.5 from central in [default]\n",
      "\torg.mongodb.spark#mongo-spark-connector_2.12;2.4.2 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-9a37d556-13cb-406e-9fce-3ec1e74014b7\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/8ms)\n",
      "23/05/11 08:43:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10-18-177-168.dynapool.wireless.nyu.edu:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>My app</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x107d91730>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pyspark\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "# Retrieve MongoDB creds\n",
    "config = dotenv_values(\"creds.env\")\n",
    "\n",
    "user = config['user']\n",
    "password = config['password']\n",
    "\n",
    "db = \"gfw\"\n",
    "\n",
    "# Connect to MongoDB\n",
    "uri = \"mongodb+srv://\" + user + \":\" + password + \"@cluster0.6jfc5iw.mongodb.net/\"\n",
    "\n",
    "# Start Spark session\n",
    "conf = pyspark.SparkConf() \\\n",
    ".set(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:2.4.2\") \\\n",
    ".setMaster(\"local\") \\\n",
    ".setAppName(\"My app\") \\\n",
    ".setAll([(\"spark.driver.memory\", \"5g\"), (\"spark.executor.memory\", \"6g\")])\n",
    "\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "\n",
    "spark = pyspark.sql.SparkSession(sc)\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63b340e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts = {}\n",
    "# counts = {'Belgian Exclusive Economic Zone2012': 0, 'Belgian Exclusive Economic Zone2013': 6151, 'Belgian Exclusive Economic Zone2014': 7682, 'Belgian Exclusive Economic Zone2015': 7492, 'Belgian Exclusive Economic Zone2016': 9618, 'Belgian Exclusive Economic Zone2017': 12192, 'Belgian Exclusive Economic Zone2018': 10922, 'Belgian Exclusive Economic Zone2019': 9031, 'Belgian Exclusive Economic Zone2020': 9434, 'Latvian Exclusive Economic Zone2012': 0, 'Latvian Exclusive Economic Zone2013': 1538}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84d59ebd-0899-4052-bf4f-2efecdfec7d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get count of fishing events in a given country/year\n",
    "country = \"Estonian Exclusive Economic Zone\"\n",
    "year = 2020\n",
    "pipeline = [\n",
    "    { \"$match\": { \"country\": country, \"year\": year } }\n",
    "]\n",
    "\n",
    "df = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\") \\\n",
    "    .option('uri', uri) \\\n",
    "    .option('database', db) \\\n",
    "    .option('collection', 'gfw') \\\n",
    "    .option('pipeline', pipeline) \\\n",
    "    .option('allowDiskUse', 'true') \\\n",
    "    .load()\n",
    "\n",
    "counts[country + str(year)] = df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "011ad01b-8fea-45c9-9cce-5c3ed789aeef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-------+----+\n",
      "|                  id|dict_value|Country|Year|\n",
      "+--------------------+----------+-------+----+\n",
      "|Belgian Exclusive...|         0|Belgium|2012|\n",
      "|Belgian Exclusive...|      6151|Belgium|2013|\n",
      "|Belgian Exclusive...|      7682|Belgium|2014|\n",
      "|Belgian Exclusive...|      7492|Belgium|2015|\n",
      "|Belgian Exclusive...|      9618|Belgium|2016|\n",
      "|Belgian Exclusive...|     12192|Belgium|2017|\n",
      "|Belgian Exclusive...|     10922|Belgium|2018|\n",
      "|Belgian Exclusive...|      9031|Belgium|2019|\n",
      "|Belgian Exclusive...|      9434|Belgium|2020|\n",
      "|Latvian Exclusive...|         0| Latvia|2012|\n",
      "|Latvian Exclusive...|      1538| Latvia|2013|\n",
      "|Latvian Exclusive...|      3040| Latvia|2014|\n",
      "|Latvian Exclusive...|      3811| Latvia|2015|\n",
      "|Latvian Exclusive...|      3207| Latvia|2016|\n",
      "|Latvian Exclusive...|      4254| Latvia|2017|\n",
      "|Latvian Exclusive...|      4722| Latvia|2018|\n",
      "|Latvian Exclusive...|      3716| Latvia|2019|\n",
      "|Latvian Exclusive...|      3597| Latvia|2020|\n",
      "|Estonian Exclusiv...|         0|Estonia|2012|\n",
      "|Estonian Exclusiv...|      1198|Estonia|2013|\n",
      "|Estonian Exclusiv...|      2039|Estonia|2014|\n",
      "|Estonian Exclusiv...|      2434|Estonia|2015|\n",
      "|Estonian Exclusiv...|      2470|Estonia|2016|\n",
      "|Estonian Exclusiv...|      3521|Estonia|2017|\n",
      "|Estonian Exclusiv...|      3450|Estonia|2018|\n",
      "|Estonian Exclusiv...|      2048|Estonia|2019|\n",
      "|Estonian Exclusiv...|         0|Estonia|2020|\n",
      "+--------------------+----------+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df.show()\n",
    "# df.count()\n",
    "# print(counts)\n",
    "from pyspark.sql.functions import split, when\n",
    "converterDict = {\"Belgian\": \"Belgium\", \"Latvian\": \"Latvia\", \"Estonian\": \"Estonia\"}\n",
    "countsDF = spark.createDataFrame([(k, v) for k, v in counts.items()], ['id', 'dict_value'])\n",
    "# Fix country and year columns\n",
    "countsDF = countsDF.withColumn('Country', split(countsDF['id'], '\\s+')[0])\n",
    "countsDF = countsDF.withColumn('Year', split(countsDF['id'], '\\s+')[3].substr(5, 8))\n",
    "for old, new in converterDict.items():\n",
    "    countsDF = countsDF.withColumn('Country', when(countsDF['Country'] == old, new).otherwise(countsDF['Country']))\n",
    "countsDF.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37bf9a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 90:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+--------+------------+-----------------+-----------+--------------------+--------------------+----------+\n",
      "|Country|Year|Arrivals|Country Code|              GDP|   Receipts|                 _id|                  id|dict_value|\n",
      "+-------+----+--------+------------+-----------------+-----------+--------------------+--------------------+----------+\n",
      "|Belgium|2013| 7684000|         BEL|0.459242192907709|14534000000|{64591b0bf8c148fb...|Belgian Exclusive...|      6151|\n",
      "|Belgium|2014| 7887000|         BEL| 1.57853314322614|15249000000|{64591b0bf8c148fb...|Belgian Exclusive...|      7682|\n",
      "|Belgium|2015| 8355000|         BEL| 2.04145900919961| 8975000000|{64591b0bf8c148fb...|Belgian Exclusive...|      7492|\n",
      "|Belgium|2016| 7481000|         BEL| 1.26668640902095| 8784000000|{64591b0bf8c148fb...|Belgian Exclusive...|      9618|\n",
      "|Belgium|2017| 8385000|         BEL|  1.6195802783878| 9636000000|{64591b0bf8c148fb...|Belgian Exclusive...|     12192|\n",
      "|Belgium|2018| 9119000|         BEL| 1.79294519302076|10319000000|{64591b0bf8c148fb...|Belgian Exclusive...|     10922|\n",
      "|Belgium|2019| 9343000|         BEL| 2.24085824041289|10581000000|{64591b0bf8c148fb...|Belgian Exclusive...|      9031|\n",
      "|Belgium|2020| 2584000|         BEL|-5.36138663334856| 7447000000|{64591b0bf8c148fb...|Belgian Exclusive...|      9434|\n",
      "|Estonia|2013| 5737000|         EST| 1.45842863615992| 2022000000|{64591b0bf8c148fb...|Estonian Exclusiv...|      1198|\n",
      "|Estonia|2014| 5804000|         EST| 3.01136658651455| 2278000000|{64591b0bf8c148fb...|Estonian Exclusiv...|      2039|\n",
      "|Estonia|2015| 5696000|         EST| 1.85302004629342| 1893000000|{64591b0bf8c148fb...|Estonian Exclusiv...|      2434|\n",
      "|Estonia|2016| 5942000|         EST| 3.15556481438308| 1911000000|{64591b0bf8c148fb...|Estonian Exclusiv...|      2470|\n",
      "|Estonia|2017| 6145000|         EST| 5.79204467466494| 2124000000|{64591b0bf8c148fb...|Estonian Exclusiv...|      3521|\n",
      "|Estonia|2018| 6033000|         EST| 3.78420084952826| 2326000000|{64591b0bf8c148fb...|Estonian Exclusiv...|      3450|\n",
      "|Estonia|2019| 6103000|         EST| 3.73970668161645| 2310000000|{64591b0bf8c148fb...|Estonian Exclusiv...|      2048|\n",
      "|Estonia|2020| 1695000|         EST|-0.55100125774716|  865000000|{64591b0bf8c148fb...|Estonian Exclusiv...|         0|\n",
      "| Latvia|2013| 5822000|         LVA| 2.00796687876637|         ..|{64591b0bf8c148fb...|Latvian Exclusive...|      1538|\n",
      "| Latvia|2014| 6246000|         LVA| 1.90217268380506|         ..|{64591b0bf8c148fb...|Latvian Exclusive...|      3040|\n",
      "| Latvia|2015| 6842000|         LVA| 3.88526005426763|         ..|{64591b0bf8c148fb...|Latvian Exclusive...|      3811|\n",
      "| Latvia|2016| 6797000|         LVA| 2.36861474664423|         ..|{64591b0bf8c148fb...|Latvian Exclusive...|      3207|\n",
      "| Latvia|2017| 7726000|         LVA| 3.31247593587459|         ..|{64591b0bf8c148fb...|Latvian Exclusive...|      4254|\n",
      "| Latvia|2018| 7775000|         LVA| 3.99185450470748|         ..|{64591b0bf8c148fb...|Latvian Exclusive...|      4722|\n",
      "| Latvia|2019| 8342000|         LVA| 2.56970388771063|         ..|{64591b0bf8c148fb...|Latvian Exclusive...|      3716|\n",
      "| Latvia|2020| 3204000|         LVA|-2.20298533825142|         ..|{64591b0bf8c148fb...|Latvian Exclusive...|      3597|\n",
      "+-------+----+--------+------------+-----------------+-----------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Get tourism data for all countries/years\n",
    "countries = [\"Belgium\", \"Latvia\", \"Estonia\"]\n",
    "years = [\"2013 [YR2013]\", \"2014 [YR2014]\", \"2015 [YR2015]\", \"2016 [YR2016]\", \"2017 [YR2017]\", \"2018 [YR2018]\", \"2019 [YR2019]\", \"2020 [YR2020]\"]\n",
    "\n",
    "pipeline = [\n",
    "    { \"$match\": { \"Country Name\": { \"$in\": countries }, \"Year\": { \"$in\": years } } }\n",
    "]\n",
    "\n",
    "df = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\") \\\n",
    "    .option('uri', uri) \\\n",
    "    .option('database', db) \\\n",
    "    .option('collection', 'tourism') \\\n",
    "    .option('pipeline', pipeline) \\\n",
    "    .option('allowDiskUse', 'true') \\\n",
    "    .load()\n",
    "# Fix up cols for consistent naming\n",
    "df = df.withColumnRenamed(\"Country Name\", \"Country\")\n",
    "df = df.withColumn(\"Year\", df[\"Year\"].substr(0, 4))\n",
    "# Join df with countsDF\n",
    "df = df.join(countsDF, [\"Country\", \"Year\"], \"inner\")\n",
    "df.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dec818c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fishing Events Correlation to GDP: -0.3130207267895838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fishing Events Correlation to Receipts: -0.4084130356607758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 140:>                (0 + 1) / 1][Stage 141:>                (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fishing Events Correlation to Arrivals: 0.5076413263605084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Check for correlation between dict_val (number of fishing events) and GDP, Arrivals\n",
    "# from pyspark.ml.feature import VectorAssembler\n",
    "# from pyspark.ml.stat import Correlation\n",
    "# Convert Arrivals, Receipts, GDP, dict_value to numeric\n",
    "df = df.withColumn(\"Arrivals\", df[\"Arrivals\"].cast(\"int\"))\n",
    "df = df.withColumn(\"Receipts\", df[\"Receipts\"].cast(\"int\"))\n",
    "df = df.withColumn(\"GDP\", df[\"GDP\"].cast(\"int\"))\n",
    "df = df.withColumn(\"dict_value\", df[\"dict_value\"].cast(\"int\"))\n",
    "print(\"Fishing Events Correlation to GDP: \" + str(df.stat.corr('dict_value', 'GDP')))\n",
    "print(\"Fishing Events Correlation to Receipts: \" + str(df.stat.corr('dict_value', 'Receipts')))\n",
    "print(\"Fishing Events Correlation to Arrivals: \" + str(df.stat.corr('dict_value', 'Arrivals')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65900a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
